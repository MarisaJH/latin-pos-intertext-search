{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook loads, evaluates, and builds a comparison table of Latin word embedding models. External models are given download scripts; models built by authors can be built using the bamman-w2v-lemma.ipynb abd bamman-w2v-lemma-tt.ipynb notebooks in this directory. (Because of a limitation with scripting large downloads from Google Drive, Bamman 2012 must be manually downloaded and places in the ```models``` directory.) Uncomment cells as needed to run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings; warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import os\n",
    "import urllib\n",
    "import shutil\n",
    "from zipfile import ZipFile\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "#import fasttext.util\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "#from cltk.stem.latin.j_v import JVReplacer\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class JVReplacer:  # pylint: disable=too-few-public-methods\n",
    "    \"\"\"Replace J/V with I/U.\n",
    "    Latin alphabet does not distinguish between J/j and I/i and V/v and U/u;\n",
    "    Yet, many texts bear the influence of later editors and the predilections of other languages.\n",
    "\n",
    "    In practical terms, the JV substitution is recommended on all Latin text preprocessing; it\n",
    "    helps to collapse the search space.\n",
    "\n",
    "    >>> replacer = JVReplacer()\n",
    "    >>> replacer.replace(\"Julius Caesar\")\n",
    "    'Iulius Caesar'\n",
    "\n",
    "    >>> replacer.replace(\"In vino veritas.\")\n",
    "    'In uino ueritas.'\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initialization for JVReplacer, reads replacement pattern tuple.\"\"\"\n",
    "        patterns = [(r\"j\", \"i\"), (r\"v\", \"u\"), (r\"J\", \"I\"), (r\"V\", \"U\")]\n",
    "        self.patterns = [(re.compile(regex), repl) for (regex, repl) in patterns]\n",
    "\n",
    "    def replace(self, text):\n",
    "        \"\"\"Do j/v replacement\"\"\"\n",
    "        for pattern, repl in self.patterns:\n",
    "            text = re.subn(pattern, repl, text)[0]\n",
    "        return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../data/evaluationsets/syn-selection-benchmark-Latin.tsv',\n",
       " <http.client.HTTPMessage at 0x126628750>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Uncomment to download\n",
    "\n",
    "## Get external data\n",
    "\n",
    "## Used with syn_selection_eval\n",
    "## Sprugnoli Rachele, Passarotti Marco, Moretti Giovanni. Vir is to Moderatus as Mulier is to Intemperans – Lemma Embeddings for Latin. 2019. https://embeddings.lila-erc.eu/\n",
    "url = 'https://embeddings.lila-erc.eu/samples/syn/syn-selection-benchmark-Latin.tsv'\n",
    "urllib.request.urlretrieve (url, '../data/evaluationsets/syn-selection-benchmark-Latin.tsv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up tools\n",
    "\n",
    "replacer = JVReplacer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up constants\n",
    "\n",
    "eval_path = '../data/evaluationsets'\n",
    "syn_eval_data = f'{eval_path}/synonyms.csv' \n",
    "syn_selection_eval_data = f'{eval_path}/syn-selection-benchmark-Latin.tsv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating on Spinelli 2018 synonyms dataset\n",
    "\n",
    "def syn_eval(model, eval_data, threshold, verbose=False):\n",
    "    # Better way than two try blocks\n",
    "    vocab_ = model.key_to_index.keys()\n",
    "    '''\n",
    "    try:\n",
    "        vocab_ = model.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    try: \n",
    "        vocab_ = model.wv.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    '''\n",
    "    with open(eval_data,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    total = len(lines)\n",
    "    matches = 0\n",
    "    for line in tqdm(lines):\n",
    "        word, syn = replacer.replace(line.strip()).split('\\t')\n",
    "        if word in vocab_:\n",
    "            most_sim = [item[0] for item in model.most_similar(word, topn=threshold)]\n",
    "            most_sim = replacer.replace(\" \".join(most_sim)).split()\n",
    "            if syn in most_sim:\n",
    "                matches += 1\n",
    "                if verbose:\n",
    "                    print(f'Synonym {syn} is in most_similar for {word}')\n",
    "    return matches/total    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for getting mean reciprocal rank on Spinelli 2018 synonyms dataset\n",
    "\n",
    "def syn_mrr(model, eval_data, threshold=100, verbose=False):\n",
    "    # Better way than two try blocks\n",
    "    vocab_ = model.key_to_index.keys()\n",
    "    '''\n",
    "    try:\n",
    "        vocab_ = model.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    try: \n",
    "        vocab_ = model.wv.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    '''\n",
    "    with open(eval_data,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    rrs = []\n",
    "    for line in tqdm(lines):\n",
    "        word, syn = replacer.replace(line.strip()).split('\\t')\n",
    "        if word in vocab_ and syn in vocab_:\n",
    "            most_sim = [item[0] for item in model.most_similar(word, topn=threshold)]\n",
    "            most_sim = replacer.replace(\" \".join(most_sim)).split()\n",
    "            if syn in most_sim:\n",
    "                rr = 1 / (most_sim.index(syn) + 1)\n",
    "                rrs.append(rr)\n",
    "    mrr = np.mean(rrs)\n",
    "    return mrr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for evaluating on LiLa synonymn selection datasheet; code based on description of evaluation method given in Sprugnoli, R., Passarotti M., Moretti G. 2019. Vir is to Moderatus as Mulier is to Intemperans – Lemma Embeddings for Latin.\n",
    "\n",
    "def syn_selection_eval(model, eval_data, verbose=False):\n",
    "    # Better way than two try blocks\n",
    "\n",
    "    vocab_ = model.key_to_index.keys()\n",
    "    '''\n",
    "    try:\n",
    "        vocab_ = model.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    try: \n",
    "        vocab_ = model.wv.vocab.keys()\n",
    "    except:\n",
    "        pass\n",
    "    '''\n",
    "    with open(eval_data,'r') as f:\n",
    "        lines = f.readlines()\n",
    "    total = 0\n",
    "    matches = 0\n",
    "    for line in tqdm(lines):\n",
    "        terms = line.split()\n",
    "        if sum([term in vocab_ for term in terms]) == 5:\n",
    "            lemma = terms[0]\n",
    "            \n",
    "            sims = [model.similarity(lemma, term) for term in terms[1:]]\n",
    "            if max(sims) == sims[0]:\n",
    "                matches += 1\n",
    "            else:\n",
    "                pass\n",
    "            total += 1\n",
    "        else:\n",
    "            pass\n",
    "    return ((matches, total), matches/total)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText Latin Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download model\n",
    "\n",
    "## Uncomment to download model for first time\n",
    "##\n",
    "# fasttext.util.download_model('la', if_exists='ignore')\n",
    "# shutil.move('cc.la.300.bin', '../models/cc.la.300.bin')\n",
    "# shutil.move('cc.la.300.bin.gz', '../models/cc.la.300.bin.gz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "\n",
    "# ft_latin = gensim.models.fasttext.load_facebook_vectors('../models/cc.la.300.bin') # Consistent interface, possible speed issues; speed issue may be related to this issue: https://github.com/RaRe-Technologies/gensim/issues/2802\n",
    "# ft_latin.vocab = {replacer.replace(k): v for k, v in ft_latin.vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Evaluation on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ft_latin\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# ft_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     ft_evals.append(syn_eval(ft_latin, syn_eval_data, threshold))\n",
    "    \n",
    "# pprint(list(zip(thresholds, ft_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_mrr = syn_mrr(ft_latin, syn_eval_data)\n",
    "# print(ft_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastText Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ft_selection = syn_selection_eval(ft_latin, syn_selection_eval_data)\n",
    "# print(ft_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bloem et al. 2020 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "\n",
    "# url = 'https://uvaauas.figshare.com/ndownloader/files/22300362'\n",
    "# urllib.request.urlretrieve (url, 'LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.zip')\n",
    "# shutil.move('LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.zip', '../models/LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.zip')\n",
    "# with ZipFile('../models/LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.zip', 'r') as zf:\n",
    "#    zf.extractall('../models')\n",
    "# os.remove('../models/LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load model\n",
    "\n",
    "# bloem_2020 = Word2Vec.load('../models/LatinArchiveOrg.ALLCONCAT.UctoNormalizedLowerCase.ShortenedToW2V.NoCarets.txt.skipgram.alpha0.025.neg5.win5.sample0.001.epochs5.mincount50.size100.model').wv\n",
    "# bloem_2020.vocab = {replacer.replace(k): v for k, v in bloem_2020.vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bloem et al. 2020 Evaluation on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = bloem_2020\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# bloem_2020_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     bloem_2020_evals.append(syn_eval(bloem_2020, syn_eval_data, threshold))\n",
    "    \n",
    "# pprint(list(zip(thresholds, bloem_2020_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bloem et al. 2020 MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloem_2020_mrr = syn_mrr(bloem_2020, syn_eval_data)\n",
    "# print(bloem_2020_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bloem et al. 2020 Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bloem_2020_selection = syn_selection_eval(bloem_2020, syn_selection_eval_data)\n",
    "# print(bloem_2020_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bamman 2012 Latin Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "\n",
    "# # For now, file must be downloaded manually and moved to ../models directory\n",
    "# url = 'https://docs.google.com/uc?id=0B5pGKi0iCsnbMm9Dd2hmb2UtbEk&export=download'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bamman_2012 = gensim.models.KeyedVectors.load_word2vec_format('../models/latin.embeddings', binary=False)\n",
    "# bamman_2012.vocab = {replacer.replace(k): v for k, v in bamman_2012.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = bamman_2012\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# bamman_2012_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     bamman_2012_evals.append(syn_eval(bamman_2012, syn_eval_data, threshold))\n",
    "    \n",
    "# pprint(list(zip(thresholds, bamman_2012_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bamman MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bamman_2012_mrr = syn_mrr(bamman_2012, syn_eval_data)\n",
    "# bamman_2012_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bamman Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bamman_2012_selection = syn_selection_eval(bamman_2012, syn_selection_eval_data)\n",
    "# bamman_2012_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LILA Lemmatized Latin W2V CBOW Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "\n",
    "# url = 'https://embeddings.lila-erc.eu/samples/download/word2vec/allLASLAlemmi-vector-100-nocase-w5-CBOW.vec'\n",
    "# urllib.request.urlretrieve (url, '../models/allLASLAlemmi-vector-100-nocase-w5-CBOW.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'allLASLAlemmi-vector-100-nocase-w5-CBOW.vec'\n",
    "# lila_w2v_cbow_2019 = gensim.models.KeyedVectors.load_word2vec_format(f'../models/{model}')\n",
    "# lila_w2v_cbow_2019.vocab = {replacer.replace(k): v for k, v in lila_w2v_cbow_2019.vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa W2V Evaluation on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lila_w2v_cbow_2019\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# lila_w2v_cbow_2019_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     lila_w2v_cbow_2019_evals.append(syn_eval(lila_w2v_cbow_2019, syn_eval_data, threshold))\n",
    "\n",
    "# pprint(list(zip(thresholds, lila_w2v_cbow_2019_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa W2V MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lila_w2v_2019_cbow_mrr = syn_mrr(lila_w2v_cbow_2019, syn_eval_data)\n",
    "# lila_w2v_2019_cbow_mrr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa W2V Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lila_w2v_2019_cbow_selection = syn_selection_eval(lila_w2v_cbow_2019, syn_selection_eval_data)\n",
    "# lila_w2v_2019_cbow_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LILA Lemmatized Latin FastText Skip Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "\n",
    "# url = 'https://embeddings.lila-erc.eu/samples/download/fasttext/allLASLA-lemmi-fast-100-SKIP-win5-min5.vec'\n",
    "# urllib.request.urlretrieve (url, '../models/allLASLA-lemmi-fast-100-SKIP-win5-min5.vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = 'allLASLA-lemmi-fast-100-SKIP-win5-min5.vec'\n",
    "# lila_ft_skip_2019 = gensim.models.KeyedVectors.load_word2vec_format(f'../models/{model}')\n",
    "# lila_ft_skip_2019.vocab = {replacer.replace(k): v for k, v in lila_ft_skip_2019.vocab.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa FT Evaluation on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = lila_ft_skip_2019\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# lila_ft_skip_2019_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     lila_ft_skip_2019_evals.append(syn_eval(lila_ft_skip_2019, syn_eval_data, threshold))\n",
    "\n",
    "# pprint(list(zip(thresholds, lila_ft_skip_2019_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa FT MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lila_ft_2019_skip_mrr = syn_mrr(lila_ft_skip_2019, syn_eval_data)\n",
    "# print(lila_ft_2019_skip_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LiLa Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lila_ft_2019_skip_selection = syn_selection_eval(lila_ft_skip_2019, syn_selection_eval_data)\n",
    "# print(lila_ft_2019_skip_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCL Lemmatized Latin Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('../models/latin_w2v_bamman_lemma300_100_1.wv.vectors.npy',\n",
       " <http.client.HTTPMessage at 0x74c689f35160>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "# # NB: See See notebook bamman-w2v-lemma.ipynb for code to this train model\n",
    "\n",
    "url = 'https://utexas.box.com/shared/static/5kc9t8t5jhca3ad83m7j4uxavrppprll'\n",
    "urllib.request.urlretrieve (url, '../models/latin_w2v_bamman_lemma300_100_1')\n",
    "url = 'https://utexas.box.com/shared/static/7vrc22fvzkw1y0m8ceb54fpzdj5vztij.npy'\n",
    "urllib.request.urlretrieve (url, '../models/latin_w2v_bamman_lemma300_100_1.trainables.syn1neg.npy')\n",
    "url = 'https://utexas.box.com/shared/static/j81h75p33t2ir7hgm2z9e9bqy6jy0uw0.npy'\n",
    "urllib.request.urlretrieve (url, '../models/latin_w2v_bamman_lemma300_100_1.wv.vectors.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qcl_2020 = Word2Vec.load('../models/latin_w2v_bamman_lemma300_100_1').wv\n",
    "#qcl_2020.vocab = {replacer.replace(k): v for k, v in qcl_2020.vocab.items()}\n",
    "# Create a new dictionary with replaced keys\n",
    "new_key_to_index = {}\n",
    "new_vectors = []\n",
    "new_index_to_key = []\n",
    "\n",
    "# Iterate through existing keys in order\n",
    "for i, key in enumerate(qcl_2020.index_to_key):\n",
    "    new_key = replacer.replace(key)\n",
    "    new_key_to_index[new_key] = i\n",
    "    new_index_to_key.append(new_key)\n",
    "    new_vectors.append(qcl_2020.vectors[i])\n",
    "\n",
    "# Update the model attributes\n",
    "qcl_2020.key_to_index = new_key_to_index\n",
    "qcl_2020.index_to_key = new_index_to_key\n",
    "qcl_2020.vectors = np.array(new_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QCL Evaluation on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2271d7aaad6f41cb931d23f9a3c58b40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4212eda89cd44debbc0b3f7244d60a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe8294f04f7840c29a649cc62874381b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12b2019af9f4d6492cbcd1be0b81a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9054d0faf504322859385eb8adac53d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fb2779d2cd4a548c92a337c19ec152",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.032460732984293195),\n",
      " (5, 0.10785340314136126),\n",
      " (10, 0.14607329842931938),\n",
      " (25, 0.20628272251308902),\n",
      " (100, 0.3078534031413613)]\n"
     ]
    }
   ],
   "source": [
    "model = qcl_2020\n",
    "\n",
    "thresholds = [1,5,10,25,100]\n",
    "qcl_2020_evals = []\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    qcl_2020_evals.append(syn_eval(qcl_2020, syn_eval_data, threshold))\n",
    "\n",
    "pprint(list(zip(thresholds, qcl_2020_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QCL MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.032460732984293195,\n",
       " 0.10785340314136126,\n",
       " 0.14607329842931938,\n",
       " 0.20628272251308902,\n",
       " 0.3078534031413613]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qcl_2020_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f661ae36be5c4ecab7cabd3249736bbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22745397255158248\n"
     ]
    }
   ],
   "source": [
    "qcl_2020_mrr = syn_mrr(qcl_2020, syn_eval_data)\n",
    "print(qcl_2020_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QCL Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/evaluationsets/syn-selection-benchmark-Latin.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m qcl_2020_selection \u001b[38;5;241m=\u001b[39m \u001b[43msyn_selection_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mqcl_2020\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msyn_selection_eval_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(qcl_2020_selection)\n",
      "Cell \u001b[0;32mIn[8], line 17\u001b[0m, in \u001b[0;36msyn_selection_eval\u001b[0;34m(model, eval_data, verbose)\u001b[0m\n\u001b[1;32m      6\u001b[0m vocab_ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mkey_to_index\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[1;32m      7\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;124;03mtry:\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    vocab_ = model.vocab.keys()\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;124;03m    pass\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43meval_data\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     18\u001b[0m     lines \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39mreadlines()\n\u001b[1;32m     19\u001b[0m total \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m/work/pi_brenocon_umass_edu/marisa/poetry_cache/virtualenvs/naacl-hlt-2021-latin-intertextuality-ZPY7aNxM-py3.9/lib/python3.9/site-packages/IPython/core/interactiveshell.py:310\u001b[0m, in \u001b[0;36m_modified_open\u001b[0;34m(file, *args, **kwargs)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[1;32m    304\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    306\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    307\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    308\u001b[0m     )\n\u001b[0;32m--> 310\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/evaluationsets/syn-selection-benchmark-Latin.tsv'"
     ]
    }
   ],
   "source": [
    "qcl_2020_selection = syn_selection_eval(qcl_2020, syn_selection_eval_data)\n",
    "print(qcl_2020_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QCL TT 2020 Latin Model (lemmatized with treetagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Download model\n",
    "# #\n",
    "# # Uncomment to download model for first time\n",
    "# # NB: See See notebook bamman-w2v-lemma-tt.ipynb for code to this train model\n",
    "\n",
    "# url = 'https://utexas.box.com/shared/static/3m1bqek9w583pkktco8vt8t6cr2lb1gu'\n",
    "# urllib.request.urlretrieve (url, '../models/latin_w2v_bamman_lemma_tt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcl_2020_tt = Word2Vec.load('../models/latin_w2v_bamman_lemma_tt').wv\n",
    "# qcl_2020_tt.vocab = {replacer.replace(k): v for k, v in qcl_2020_tt.vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = qcl_2020_tt\n",
    "\n",
    "# thresholds = [1,5,10,25,100]\n",
    "# qcl_2020_tt_evals = []\n",
    "\n",
    "# for threshold in tqdm(thresholds):\n",
    "#     qcl_2020_tt_evals.append(syn_eval(qcl_2020_tt, syn_eval_data, threshold))\n",
    "\n",
    "# pprint(list(zip(thresholds, qcl_2020_tt_evals)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QCL TT 2020 MRR on synonym list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcl_2020_tt_mrr = syn_mrr(qcl_2020_tt, syn_eval_data)\n",
    "# print(qcl_2020_tt_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QCL TT 2020 Evaluation on synonym selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qcl_2020_tt_selection = syn_selection_eval(qcl_2020_tt, syn_selection_eval_data)\n",
    "# print(qcl_2020_tt_selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CC100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load w2v model\n",
    "\n",
    "cc100 = Word2Vec.load('../models/latin_w2v_cc100_lemma300_100_1').wv\n",
    "\n",
    "# Create a new dictionary with replaced keys\n",
    "new_key_to_index = {}\n",
    "new_vectors = []\n",
    "new_index_to_key = []\n",
    "\n",
    "# Iterate through existing keys in order\n",
    "for i, key in enumerate(cc100.index_to_key):\n",
    "    new_key = replacer.replace(key)\n",
    "    new_key_to_index[new_key] = i\n",
    "    new_index_to_key.append(new_key)\n",
    "    new_vectors.append(cc100.vectors[i])\n",
    "\n",
    "# Update the model attributes\n",
    "cc100.key_to_index = new_key_to_index\n",
    "cc100.index_to_key = new_index_to_key\n",
    "cc100.vectors = np.array(new_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa49702c03cf4a5ea26ba5904dcb36f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f99d4fae178476aae8e7d3ab59a9d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a11d4cf7cb443218f7c60ace053de1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cdc461f685d4593a50fd4818b94b1fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86dbbde03c12480a94be3e69b73cf525",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4219a2917d7f43d7b280fbacafa7a443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 0.03769633507853403),\n",
      " (5, 0.11727748691099477),\n",
      " (10, 0.15392670157068064),\n",
      " (25, 0.21675392670157068),\n",
      " (100, 0.32094240837696336)]\n"
     ]
    }
   ],
   "source": [
    "model = cc100\n",
    "\n",
    "thresholds = [1,5,10,25,100]\n",
    "cc100_evals = []\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    cc100_evals.append(syn_eval(cc100, syn_eval_data, threshold))\n",
    "\n",
    "pprint(list(zip(thresholds, cc100_evals)))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.03769633507853403,\n",
       " 0.11727748691099477,\n",
       " 0.15392670157068064,\n",
       " 0.21675392670157068,\n",
       " 0.32094240837696336]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc100_evals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c1a67b259594e9a9a383c094f3e268a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1910 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23921756499806365\n"
     ]
    }
   ],
   "source": [
    "cc100_mrr = syn_mrr(cc100, syn_eval_data)\n",
    "print(cc100_mrr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 0.005235602094240836\n",
      "5: 0.00942408376963351\n",
      "10: 0.007853403141361265\n",
      "25: 0.010471204188481659\n",
      "100: 0.01308900523560208\n"
     ]
    }
   ],
   "source": [
    "# diff (cc100 - qcl_2020)\n",
    "for i in range(len(cc100_evals)):\n",
    "    rank = thresholds[i]\n",
    "    cc100_score = cc100_evals[i]\n",
    "    qcl_2020_score = qcl_2020_evals[i]\n",
    "    print(f'{rank}: {cc100_score - qcl_2020_score}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.011763592446481175\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# mrr diff\n",
    "print(cc100_mrr - qcl_2020_mrr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "from bert_utils import BERTWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AutoTokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m \u001b[43mAutoTokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbowphs/LaBerta\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m bert_model \u001b[38;5;241m=\u001b[39m AutoModelForMaskedLM\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbowphs/LaBerta\u001b[39m\u001b[38;5;124m'\u001b[39m, output_hidden_states\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m laberta \u001b[38;5;241m=\u001b[39m BERTWrapper(bert_model, tokenizer)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AutoTokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bowphs/LaBerta')\n",
    "bert_model = AutoModelForMaskedLM.from_pretrained('bowphs/LaBerta', output_hidden_states=True)\n",
    "laberta = BERTWrapper(bert_model, tokenizer)\n",
    "\n",
    "eval_words = set()\n",
    "with open(syn_eval_data, 'r') as f:\n",
    "    for line in f:\n",
    "        word, syn = replacer.replace(line.strip()).split('\\t')\n",
    "        eval_words.add(word)\n",
    "        eval_words.add(syn)\n",
    "\n",
    "cache_file = \"laberta_embeddings_cache.pt\"\n",
    "laberta.precompute_embeddings(\n",
    "    list(eval_words),\n",
    "    batch_size=32,\n",
    "    cache_file=cache_file\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = laberta\n",
    "thresholds = [1,5,10,25,100]\n",
    "bert_evals = []\n",
    "\n",
    "for threshold in tqdm(thresholds):\n",
    "    bert_evals.append(syn_eval(laberta, syn_eval_data, threshold))\n",
    "    \n",
    "pprint(list(zip(thresholds, bert_evals)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_mrr = syn_mrr(laberta, syn_eval_data)\n",
    "print(bert_mrr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cached results; save time while working\n",
    "\n",
    "bamman_2012_evals = [.004, .016, .021, .033, .058] # last run 4/8/2021\n",
    "ft_evals = [.002, .007, .012, .017, .046] # last run 4/8/2021\n",
    "lila_w2v_cbow_2019_evals = [.024, .081, .113, .159, .271] # last run 4/8/2021\n",
    "lila_ft_skip_2019_evals = [.017, .062, .093, .143, .229] # last run 4/8/2021\n",
    "bloem_2020_evals = [.003, .019, .039, .070, .146] # last run 4/8/2021\n",
    "qcl_2020_evals = [.032, .107, .145, .204, .307] # last run 4/8/2021\n",
    "qcl_2020_tt_evals = [.035, .107, .150, .210, .349] # last run 4/8/2021\n",
    "\n",
    "bamman_2012_mrr = .175 # last run 4/8/2021\n",
    "ft_mrr = .118 # last run 4/8/2021\n",
    "lila_w2v_2019_cbow_mrr = .198 # last run 4/8/2021\n",
    "lila_ft_2019_skip_mrr = .182 # last run 4/8/2021\n",
    "bloem_2020_mrr = .101 # last run 4/8/2021\n",
    "qcl_2020_mrr = .227 # last run 4/8/2021\n",
    "qcl_2020_tt_mrr = .206 # last run 4/8/2021\n",
    "\n",
    "bamman_2012_selection = ((1546, 2320), 0.6663793103448276) # last run 4/8/2021\n",
    "ft_selection = ((331, 447), 0.7404921700223713) # last run 4/8/2021\n",
    "lila_w2v_2019_cbow_selection = ((1420, 1750), 0.8114285714285714) # last run 4/8/2021\n",
    "lila_ft_2019_skip_selection = ((1521, 1750), 0.8691428571428571) # last run 4/8/2021\n",
    "bloem_2020_selection = ((1498, 1766), 0.8482446206115515) # last run 4/8/2021\n",
    "qcl_2020_selection = ((772, 909), 0.8492849284928493) # last run 4/8/2021\n",
    "qcl_2020_tt_selection = ((840, 958), 0.8768267223382046) # last run 4/8/2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bamman 2012</th>\n",
       "      <th>FastText</th>\n",
       "      <th>Lila 2019 W2V CBOW</th>\n",
       "      <th>Bloem 2020</th>\n",
       "      <th>QCL 2020</th>\n",
       "      <th>Lila 2019 FT Skip</th>\n",
       "      <th>QCL 2020 TT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.003</td>\n",
       "      <td>0.032</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.007</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.107</td>\n",
       "      <td>0.062</td>\n",
       "      <td>0.107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.021</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.113</td>\n",
       "      <td>0.039</td>\n",
       "      <td>0.145</td>\n",
       "      <td>0.093</td>\n",
       "      <td>0.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.033</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.159</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.204</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.058</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.271</td>\n",
       "      <td>0.146</td>\n",
       "      <td>0.307</td>\n",
       "      <td>0.229</td>\n",
       "      <td>0.349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRR</th>\n",
       "      <td>0.175</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.198</td>\n",
       "      <td>0.101</td>\n",
       "      <td>0.227</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Selection</th>\n",
       "      <td>0.666</td>\n",
       "      <td>0.740</td>\n",
       "      <td>0.811</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.869</td>\n",
       "      <td>0.877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Bamman 2012  FastText  Lila 2019 W2V CBOW  Bloem 2020  QCL 2020  \\\n",
       "1                0.004     0.002               0.024       0.003     0.032   \n",
       "5                0.016     0.007               0.081       0.019     0.107   \n",
       "10               0.021     0.012               0.113       0.039     0.145   \n",
       "25               0.033     0.017               0.159       0.070     0.204   \n",
       "100              0.058     0.046               0.271       0.146     0.307   \n",
       "MRR              0.175     0.118               0.198       0.101     0.227   \n",
       "Selection        0.666     0.740               0.811       0.848     0.849   \n",
       "\n",
       "           Lila 2019 FT Skip  QCL 2020 TT  \n",
       "1                      0.017        0.035  \n",
       "5                      0.062        0.107  \n",
       "10                     0.093        0.150  \n",
       "25                     0.143        0.210  \n",
       "100                    0.229        0.349  \n",
       "MRR                    0.182        0.206  \n",
       "Selection              0.869        0.877  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_names = ['FastText', 'Bamman 2012', 'Lila 2019 W2V CBOW', 'Lila 2019 FT Skip', 'QCL 2020', 'QCL 2020 TT', 'Bloem 2020']\n",
    "index_labels = [1, 5, 10, 25, 100, 'MRR', 'Selection']\n",
    "\n",
    "data = [\n",
    "    ft_evals + [ft_mrr, ft_selection[1]],\n",
    "    bamman_2012_evals + [bamman_2012_mrr, bamman_2012_selection[1]],\n",
    "    lila_w2v_cbow_2019_evals + [lila_w2v_2019_cbow_mrr, lila_w2v_2019_cbow_selection[1]],\n",
    "    lila_ft_skip_2019_evals + [lila_ft_2019_skip_mrr, lila_ft_2019_skip_selection[1]],\n",
    "    qcl_2020_evals + [qcl_2020_mrr, qcl_2020_selection[1]],\n",
    "    qcl_2020_tt_evals + [qcl_2020_tt_mrr, qcl_2020_tt_selection[1]],\n",
    "    bloem_2020_evals + [bloem_2020_mrr, bloem_2020_selection[1]],\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(data).round(3)\n",
    "df.index = model_names\n",
    "df.columns = index_labels\n",
    "df = df.sort_values(by=['Selection'])\n",
    "df = df.T\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "naacl-hlt-2021-latin-intertextuality-ZPY7aNxM-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
